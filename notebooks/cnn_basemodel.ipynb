{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbce3587",
   "metadata": {},
   "source": [
    "# Final Project - Piano Roll Extraction -SRC\n",
    "- Course: AAI-511-Neural Networks\n",
    "- Institution: University of San Diego\n",
    "- Professor: Kahila Mokhtari Jadid\n",
    "- Group 4 Members: \n",
    "    * Lucas Young\n",
    "    * Titouan Margret\n",
    "    * Juan Pablo Triana Martinez\n",
    "\n",
    "This notebook has the intention to follow `data_piano_roll_extraction.ipynb`, but using `src` folder with all functions and classes\n",
    "\n",
    "The following document contains the following:\n",
    "1. Download *Flavia Dataset* from USD course assignment, else message the zip file is not present.\n",
    "2. Extract all folders containing Images and labels from `M4-archive.zip`.\n",
    "3. Loading dataset into `torch.Tensor` and `pandas.DataFrame` when necessary.\n",
    "4. Pre-processing and cleaning of the data with necessary transformations -> (fized size, grayscale)\n",
    "5. Split the data into `train_set` and `test_set` using an 80:20 ratio.\n",
    "6. We would set up a `train_dataset` and `test_dataset` using `torch.utils.data.Dataset` and `torchvision.transforms`\n",
    "7. We would set up a `train_dataloader` and `test_dataloader` using `torch.utils.data.Dataloader` with Batch size = 32.\n",
    "8. Setup a `torch.nn` CNN model with the following characteristics:\n",
    "    - Optimizer: Adam with lr = 0.001\n",
    "    - Loss function: Cross Entrpy Loss.\n",
    "    - Same number of layers, we would change the \n",
    "9. Plot the `train_loss` and `test_loss`, combined with proper metrics: (Accuracy, Precision, Recall, F1-score)\n",
    "10. Using that trained model, visualize the learned features across different "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
